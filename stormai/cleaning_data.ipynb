{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './posts_rows.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./posts_rows.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost_order\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/openaipy/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/openaipy/lib/python3.13/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniconda3/envs/openaipy/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/openaipy/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniconda3/envs/openaipy/lib/python3.13/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './posts_rows.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/posts_rows.csv\")\n",
    "df = df.sort_values(by=\"post_order\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>user_id</th>\n",
       "      <th>tag</th>\n",
       "      <th>image_urls</th>\n",
       "      <th>summary</th>\n",
       "      <th>post_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>56c08225-a216-4c92-9481-bdf9c396913c</td>\n",
       "      <td>22/10/2024</td>\n",
       "      <td>Strom Drain Version One</td>\n",
       "      <td>Today I have started the creation of my own pe...</td>\n",
       "      <td>fbc72f17-b191-48a6-86ab-54ed20be6cf1</td>\n",
       "      <td>project-progress</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>612c56d6-78f7-4dda-a81b-a93b8a7f85be</td>\n",
       "      <td>22/10/2024</td>\n",
       "      <td>Search Algorithm of Life</td>\n",
       "      <td>I was thinking a lot today about how I approac...</td>\n",
       "      <td>fbc72f17-b191-48a6-86ab-54ed20be6cf1</td>\n",
       "      <td>thoughts</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>fdedbbc8-5198-4a79-b3fb-a70336c83254</td>\n",
       "      <td>23/10/2024</td>\n",
       "      <td>Demo Advice</td>\n",
       "      <td>Angus just told me when demoing a project to a...</td>\n",
       "      <td>fbc72f17-b191-48a6-86ab-54ed20be6cf1</td>\n",
       "      <td>thoughts</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>c693fe03-08e6-414b-9aa3-f17095a789b7</td>\n",
       "      <td>23/10/2024</td>\n",
       "      <td>Stormdrain progress</td>\n",
       "      <td>I have been able to get the frontend to talk t...</td>\n",
       "      <td>fbc72f17-b191-48a6-86ab-54ed20be6cf1</td>\n",
       "      <td>project-progress</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>a9c73ec7-b053-4d38-ba2d-b2fd06cfe5cd</td>\n",
       "      <td>23/10/2024</td>\n",
       "      <td>useRef Hook</td>\n",
       "      <td>After watching a tutorial trying to figure out...</td>\n",
       "      <td>fbc72f17-b191-48a6-86ab-54ed20be6cf1</td>\n",
       "      <td>frontend-learning</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>133fefcd-c37c-4dbd-977c-e9566478b665</td>\n",
       "      <td>13/11/2024</td>\n",
       "      <td>Terminology Alert!!!</td>\n",
       "      <td>Be aware in the nextjs documentation api route...</td>\n",
       "      <td>fbc72f17-b191-48a6-86ab-54ed20be6cf1</td>\n",
       "      <td>frontend-learning</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>d0381848-5c8e-4240-afcd-e459f335420e</td>\n",
       "      <td>13/11/2024</td>\n",
       "      <td>ML Projects</td>\n",
       "      <td>The two big projects I will do in order or get...</td>\n",
       "      <td>fbc72f17-b191-48a6-86ab-54ed20be6cf1</td>\n",
       "      <td>machine-learning</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>53fbf4df-fbbc-4573-9c5e-aac15af10f2b</td>\n",
       "      <td>14/11/2024</td>\n",
       "      <td>Data Engineer AI App</td>\n",
       "      <td>After speaking with Angus about his supercord ...</td>\n",
       "      <td>fbc72f17-b191-48a6-86ab-54ed20be6cf1</td>\n",
       "      <td>thoughts</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>db0c5775-8dea-4523-a6f0-a11f4d5416f4</td>\n",
       "      <td>14/11/2024</td>\n",
       "      <td>Azure Storage Accounts</td>\n",
       "      <td>Yesterday and today I have gone through the le...</td>\n",
       "      <td>fbc72f17-b191-48a6-86ab-54ed20be6cf1</td>\n",
       "      <td>azure-data-engineer</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>5e088ff7-4285-47c2-a57c-f1aceb1efeb7</td>\n",
       "      <td>15/11/2024</td>\n",
       "      <td>Fixed Habits</td>\n",
       "      <td>Today I fixed the api issue with habits replac...</td>\n",
       "      <td>fbc72f17-b191-48a6-86ab-54ed20be6cf1</td>\n",
       "      <td>project-progress</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  post_id        date  \\\n",
       "33   56c08225-a216-4c92-9481-bdf9c396913c  22/10/2024   \n",
       "44   612c56d6-78f7-4dda-a81b-a93b8a7f85be  22/10/2024   \n",
       "123  fdedbbc8-5198-4a79-b3fb-a70336c83254  23/10/2024   \n",
       "95   c693fe03-08e6-414b-9aa3-f17095a789b7  23/10/2024   \n",
       "73   a9c73ec7-b053-4d38-ba2d-b2fd06cfe5cd  23/10/2024   \n",
       "..                                    ...         ...   \n",
       "8    133fefcd-c37c-4dbd-977c-e9566478b665  13/11/2024   \n",
       "99   d0381848-5c8e-4240-afcd-e459f335420e  13/11/2024   \n",
       "32   53fbf4df-fbbc-4573-9c5e-aac15af10f2b  14/11/2024   \n",
       "107  db0c5775-8dea-4523-a6f0-a11f4d5416f4  14/11/2024   \n",
       "38   5e088ff7-4285-47c2-a57c-f1aceb1efeb7  15/11/2024   \n",
       "\n",
       "                        title  \\\n",
       "33    Strom Drain Version One   \n",
       "44   Search Algorithm of Life   \n",
       "123              Demo Advice    \n",
       "95        Stormdrain progress   \n",
       "73                useRef Hook   \n",
       "..                        ...   \n",
       "8        Terminology Alert!!!   \n",
       "99                ML Projects   \n",
       "32       Data Engineer AI App   \n",
       "107    Azure Storage Accounts   \n",
       "38               Fixed Habits   \n",
       "\n",
       "                                                  body  \\\n",
       "33   Today I have started the creation of my own pe...   \n",
       "44   I was thinking a lot today about how I approac...   \n",
       "123  Angus just told me when demoing a project to a...   \n",
       "95   I have been able to get the frontend to talk t...   \n",
       "73   After watching a tutorial trying to figure out...   \n",
       "..                                                 ...   \n",
       "8    Be aware in the nextjs documentation api route...   \n",
       "99   The two big projects I will do in order or get...   \n",
       "32   After speaking with Angus about his supercord ...   \n",
       "107  Yesterday and today I have gone through the le...   \n",
       "38   Today I fixed the api issue with habits replac...   \n",
       "\n",
       "                                  user_id                  tag image_urls  \\\n",
       "33   fbc72f17-b191-48a6-86ab-54ed20be6cf1     project-progress         []   \n",
       "44   fbc72f17-b191-48a6-86ab-54ed20be6cf1             thoughts         []   \n",
       "123  fbc72f17-b191-48a6-86ab-54ed20be6cf1             thoughts         []   \n",
       "95   fbc72f17-b191-48a6-86ab-54ed20be6cf1     project-progress         []   \n",
       "73   fbc72f17-b191-48a6-86ab-54ed20be6cf1    frontend-learning         []   \n",
       "..                                    ...                  ...        ...   \n",
       "8    fbc72f17-b191-48a6-86ab-54ed20be6cf1    frontend-learning         []   \n",
       "99   fbc72f17-b191-48a6-86ab-54ed20be6cf1     machine-learning         []   \n",
       "32   fbc72f17-b191-48a6-86ab-54ed20be6cf1             thoughts         []   \n",
       "107  fbc72f17-b191-48a6-86ab-54ed20be6cf1  azure-data-engineer         []   \n",
       "38   fbc72f17-b191-48a6-86ab-54ed20be6cf1     project-progress         []   \n",
       "\n",
       "     summary  post_order  \n",
       "33       NaN           1  \n",
       "44       NaN           2  \n",
       "123      NaN           3  \n",
       "95       NaN           4  \n",
       "73       NaN           5  \n",
       "..       ...         ...  \n",
       "8        NaN          96  \n",
       "99       NaN          97  \n",
       "32       NaN          98  \n",
       "107      NaN          99  \n",
       "38       NaN         100  \n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33     Today I have started the creation of my own pe...\n",
       "44     I was thinking a lot today about how I approac...\n",
       "123    Angus just told me when demoing a project to a...\n",
       "95     I have been able to get the frontend to talk t...\n",
       "73     After watching a tutorial trying to figure out...\n",
       "Name: body, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body = df[\"body\"]\n",
    "body.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_KEY = os.getenv('OPENAI_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    api_key=OPENAI_KEY\n",
    ")\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "   text = text.replace(\"\\n\", \" \") # Replace all newlines with spaces for better embeddings \n",
    "   return client.embeddings.create(input = [text], model=model).data[0].embedding # Get the embedding by calling api using wrapper\n",
    "\n",
    "# Create the combined column allowing us to embed the title and the body of each post\n",
    "df['combined'] = (\n",
    "    \"Title: \" + df.title.str.strip() + \"; Content: \" + df.body.str.strip().apply(lambda x: x.replace(\"\\n\", \" \"))\n",
    ")\n",
    "\n",
    "# Add the embedding column that we want\n",
    "df['embedding'] = df.combined.apply(lambda x: get_embedding(x, model='text-embedding-3-small'))\n",
    "# Save the new rows to the csv\n",
    "df.to_csv('./data/posts-with-embeddings.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Title: Confidence vs Prediction Intervals; Content: I finished off the Applied Statistics for Machine Learning Engineers video from mike west and it covered a lot!  I will definitely need to sit down and review the content in the future but I think I will hold off until I have completed the entire course. Today what I learned was the there are there main types of intervals we look at, tolerance, confidence and prediction.  Prediction intervals define our uncertainty or certainty in a models prediction, while confidence intervals focus on the certainty in a specific model parameter say the mean or std. Mike provided a great diagram to understand the difference between the two of these. With tolerance interval, I am still a little confused.  After a little more research, I think that I understand it more.  Essentially it looks at the observed values as a whole as opposed to a single prediction or a parameter like prediction and confidence intervals.  A tolerance interval makes a statement about the data as a whole e.g. 90% of all observations will fall between 10 and 20. I think it mkaes much more sense now.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the combined column allowing us to embed the title and the body of each post\n",
    "df['combined'] = (\n",
    "    \"Title: \" + df.title.str.strip() + \"; Content: \" + df.body.str.strip().apply(lambda x: x.replace(\"\\n\", \" \"))\n",
    ")\n",
    "\n",
    "df['combined'][20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Format\n",
    "After testing a few prompts for summarisation on gpt 4 mini I have found one that seems to achieve what I am looking for in my blog TLDR summarisations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Please provide a TLDR summary of the following content in one sentence: [insert combined title and body of post here with /n stripped] The summary should capture the main points and give an overview of the key activities or plans mentioned.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "def get_summary(combined):\n",
    "    \n",
    "    prompt = f\"Please provide a TLDR summary of the following content in one sentence: {combined} The summary should capture the main points and give an overview of the key activities or plans mentioned.\"\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return chat_completion\n",
    "\n",
    "\n",
    "# Add the embedding column that we want\n",
    "df['summary'] = df.combined.apply(lambda x: get_summary(x))\n",
    "# save the resulting dataframe to a csv for analysis and to reupload to database when completed\n",
    "df.to_csv('./data/posts-with-embeddings-and-summary.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openaipy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
